# 开源开放的大模型

旨在记录全球开源开放大模型发展情况，欢迎提供
- *线索*
- *材料*
- *PR*
- *Issue*


## 基础大模型
|序号|名称|参数规模|数据规模|说明|
|:-|:-|:-|:-|:-|
|1|[LLaMA](Open-LLMs/llama.md)|7B,13B,30B,65B|1.4T|Meta，代码开源，模型“泄露”,不可商用，[详细介绍](https://mp.weixin.qq.com/s/dKInMi6P80GXecUtR3WQsA)|
|2|[LLaMA-2](Open-LLMs/llama2.md)|7B,13B,70B|2T|可商用|
|3|[BLOOM](Open-LLMs/bloom.md)|3B,7.1B,176B|366B|可商用，最为宽松，[详细介绍](https://mp.weixin.qq.com/s/ia-yrmXbnlooRA3K1hoTwQ)|
|4|GALACTICA|6.7B,30B,120B||
|5|[Falcon](Open-LLMs/falcon.md)|7B,40B||
|6|MOSS|16B||
|7|ChatGLM|6B|||
|8|StableLM|3B,7B|800B||
|9|[baichuan](Open-LLMs/baichuan.md)|7B,13B|1.2T|开放，商用需授权|
|10|Aquila|7B,33B||悟道·天鹰|
|11|RedPajama|3B,7B|||
|12|GPT-NeoX|20B|800GB的[The Pile](https://arxiv.org/abs/2101.00027)数据集||
|13|OpenLLaMA|3B,7B,13B|1T||
|14|MPT|7B,30B|1T|
|15|Pythia|2.8B,6.9B,12B|300B||
|16|XGen|7B|1.5T||
|17|OPT|6.7B,13B,30B,66B,175B|||
|18|elpis|6.7B,13B||天云数据|

## 非基础大模型
- WizardLM
- Alpaca
- Vicuna
- Guanaco



## 模型架构

- [GPTQ](https://github.com/IST-DASLab/gptq)


